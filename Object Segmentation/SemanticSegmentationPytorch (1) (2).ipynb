{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AbTeDP5Tbou"
      },
      "source": [
        "# Segmentation\n",
        "\n",
        "There are different neural architectures for segmentation, but they all have the same structure:\n",
        "\n",
        "* **Encoder** 입력 이미지에서 특징을 추출\n",
        "* **Decoder** 특징을 클래스 수에 해당하는 동일한 크기와 채널 수를 가진 **마스크 이미지**로 변환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequsites\n",
        "\n",
        "To begin with, we will import required libraries, and check if there is GPU available for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T15:48:06.861688Z",
          "iopub.status.busy": "2022-04-08T15:48:06.861254Z",
          "iopub.status.idle": "2022-04-08T15:48:06.868219Z",
          "shell.execute_reply": "2022-04-08T15:48:06.867567Z",
          "shell.execute_reply.started": "2022-04-08T15:48:06.861644Z"
        },
        "id": "tv1T3XemFMpE",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: scikit-image in /Users/leemac/Library/Python/3.9/lib/python/site-packages (0.22.0)\n",
            "Requirement already satisfied: pillow>=9.0.1 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from scikit-image) (10.3.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from scikit-image) (3.2.1)\n",
            "Requirement already satisfied: lazy_loader>=0.3 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: imageio>=2.27 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from scikit-image) (2.34.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.8 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from scikit-image) (2024.5.22)\n",
            "Requirement already satisfied: packaging>=21 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from scikit-image) (24.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch==2.0.1 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (2.0.1)\n",
            "Requirement already satisfied: torchvision==0.15.2 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (0.15.2)\n",
            "Requirement already satisfied: networkx in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1) (3.2.1)\n",
            "Requirement already satisfied: filelock in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1) (3.14.0)\n",
            "Requirement already satisfied: sympy in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1) (4.12.0)\n",
            "Requirement already satisfied: jinja2 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from torch==2.0.1) (3.1.4)\n",
            "Requirement already satisfied: numpy in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from torchvision==0.15.2) (1.26.4)\n",
            "Requirement already satisfied: requests in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from torchvision==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from torchvision==0.15.2) (10.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from requests->torchvision==0.15.2) (2024.2.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from requests->torchvision==0.15.2) (3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from requests->torchvision==0.15.2) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from requests->torchvision==0.15.2) (2.2.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tqdm in /Users/leemac/Library/Python/3.9/lib/python/site-packages (4.66.4)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.9.0-cp39-cp39-macosx_11_0_arm64.whl (7.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8 MB 5.4 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pillow>=8 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.3.0)\n",
            "Collecting kiwisolver>=1.3.1\n",
            "  Downloading kiwisolver-1.4.5-cp39-cp39-macosx_11_0_arm64.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 11.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting importlib-resources>=3.2.0\n",
            "  Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.2.1-cp39-cp39-macosx_11_0_arm64.whl (244 kB)\n",
            "\u001b[K     |████████████████████████████████| 244 kB 25.8 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from matplotlib) (24.0)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting pyparsing>=2.3.1\n",
            "  Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 18.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.52.4-cp39-cp39-macosx_11_0_arm64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 23.6 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /Users/leemac/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.19.0)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Installing collected packages: pyparsing, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
            "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.52.4 importlib-resources-6.4.0 kiwisolver-1.4.5 matplotlib-3.9.0 pyparsing-3.1.2\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install scikit-image\n",
        "%pip install torch==2.0.1 torchvision==0.15.2\n",
        "%pip install tqdm\n",
        "%pip install matplotlib\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from tqdm import tqdm # 진행 상황 표시기를 추가\n",
        "import numpy as np\n",
        "import torch.nn.functional as F # PyTorch의 함수형 API를 사용\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "\n",
        "# 시드 설정의 중요성\n",
        "# 재현 가능성: 동일한 시드 값이 사용되면, 코드 실행 시 동일한 난수 생성 패턴이 유지됨\n",
        "#    모델 훈련 결과가 일관되게 유지되도록 함\n",
        "# 디버깅 용이성: 결과가 일관되면 디버깅이 훨씬 쉬워짐\n",
        "#    예를 들어, 모델이 특정 에포크에서 이상한 동작을 보일 경우, 같은 시드로 다시 실행하여 그 에포크의 상태를 쉽게 조사할 수 있음\n",
        "# 이 설정은 모델을 반복적으로 실행하면서 동일한 결과를 얻고자 할 때 유용\n",
        "#    PyTorch와 NumPy 모두 시드 설정을 통해 난수 생성의 일관성을 유지할 수 있음\n",
        "\n",
        "torch.manual_seed(42) # PyTorch의 난수 생성기의 시드를 42로 설정하여 실험의 재현 가능성을 보장\n",
        "np.random.seed(42) # NumPy의 난수 생성기의 시드를 42로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T16:03:32.933989Z",
          "iopub.status.busy": "2022-04-08T16:03:32.933733Z",
          "iopub.status.idle": "2022-04-08T16:03:32.937996Z",
          "shell.execute_reply": "2022-04-08T16:03:32.937366Z",
          "shell.execute_reply.started": "2022-04-08T16:03:32.933959Z"
        },
        "id": "xhSEogpDFMpK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "train_size = 0.9 # train_size: 전체 데이터셋 중 훈련에 사용할 데이터의 비율 - 0.9로 설정되었으므로 90%의 데이터를 훈련에 사용하고, 나머지 10%를 검증 또는 테스트에 사용\n",
        "lr = 1e-3 # 학습률\n",
        "weight_decay = 1e-6 # 가중치 감쇠 - L2 정규화 항을 통해 가중치를 줄이는 데 사용\n",
        "batch_size = 32 # 훈련 중 한 번에 처리할 데이터 샘플의 수를 의미\n",
        "epochs = 30 # 전체 데이터셋을 몇 번 반복하여 훈련할지를 의미"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4if75qwFMpJ"
      },
      "source": [
        "## The Dataset\n",
        "\n",
        "- 인간 모반의 더모스코픽 이미지에 대한 PH<sup>2</sup> 데이터베이스를 사용\n",
        "- 이 데이터 세트에는 전형적인 모반, 비정형 모반, 흑색종 등 세 가지 유형의 모반에 대한 200개의 이미지가 포함되어 있음\n",
        "- 모든 이미지에는 모반의 윤곽을 나타내는 해당 **마스크**도 포함되어 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T16:47:25.071036Z",
          "iopub.status.busy": "2022-04-08T16:47:25.070746Z",
          "iopub.status.idle": "2022-04-08T16:47:32.612115Z",
          "shell.execute_reply": "2022-04-08T16:47:32.611253Z",
          "shell.execute_reply.started": "2022-04-08T16:47:25.071005Z"
        },
        "id": "TkuYGLRKFMpK",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=087fce3c96080ebece526aa5914ddba8667661f9ecce3b26fe0102dcdde7d9fb\n",
            "  Stored in directory: /Users/leemac/Library/Caches/pip/wheels/04/5f/3e/46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting unrar\n",
            "  Downloading unrar-0.4-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: unrar\n",
            "Successfully installed unrar-0.4\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "zsh:1: command not found: wget\n",
            "zsh:1: command not found: unrar\n"
          ]
        }
      ],
      "source": [
        "# terminal에서 sudo apt-get install unrar\n",
        "%pip install wget\n",
        "%pip install unrar\n",
        "\n",
        "!wget https://www.dropbox.com/s/k88qukc20ljnbuo/PH2Dataset.rar\n",
        "!unrar x -Y PH2Dataset.rar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 이제 데이터 세트를 로드하는 코드를 정의\n",
        "- 모든 이미지를 256x256 크기로 변환하고 데이터 세트를 훈련과 테스트 부분으로 분할\n",
        "- 이 함수는 모반의 윤곽을 나타내는 원본 이미지와 마스크가 각각 포함된 훈련 및 테스트 데이터 세트를 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Rumy9ldAFteW"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 1 is not equal to len(dims) = 4",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m     test_dataset \u001b[38;5;241m=\u001b[39m (images[test_ind, :, :, :], masks[test_ind, :, :, :])\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_dataset, test_dataset\n\u001b[0;32m---> 34\u001b[0m train_dataset, test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[6], line 17\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(train_part, root)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 로드한 이미지와 마스크를 (256, 256) 크기로 리사이즈\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 이미지는 (N, C, H, W) 형식으로 변환하고, 마스크는 이진화하여 (N, 1, H, W) 형식으로 변환\u001b[39;00m\n\u001b[1;32m     16\u001b[0m size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manti_aliasing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m masks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(np\u001b[38;5;241m.\u001b[39marray([resize(mask, size, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m, anti_aliasing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mask \u001b[38;5;129;01min\u001b[39;00m masks]))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 데이터셋을 무작위로 섞고, train_part 비율에 따라 학습용 데이터와 테스트용 데이터로 나눔\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 1 is not equal to len(dims) = 4"
          ]
        }
      ],
      "source": [
        "def load_dataset(train_part, root='PH2Dataset'): # train_part 비율과 데이터가 위치한 루트 폴더를 인자로 받음\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    # PH2 Dataset images 폴더를 순회하면서 _Dermoscopic_Image로 끝나는 폴더에서 이미지를, _lesion으로 끝나는 폴더에서 마스크 이미지를 로드\n",
        "\n",
        "    for root, dirs, files in os.walk(os.path.join(root, 'PH2 Dataset images')):\n",
        "        if root.endswith('_Dermoscopic_Image'):\n",
        "            images.append(imread(os.path.join(root, files[0])))\n",
        "        if root.endswith('_lesion'):\n",
        "            masks.append(imread(os.path.join(root, files[0])))\n",
        "\n",
        "    # 로드한 이미지와 마스크를 (256, 256) 크기로 리사이즈\n",
        "    # 이미지는 (N, C, H, W) 형식으로 변환하고, 마스크는 이진화하여 (N, 1, H, W) 형식으로 변환\n",
        "\n",
        "    size = (256, 256)\n",
        "    images = torch.permute(torch.FloatTensor(np.array([resize(image, size, mode='constant', anti_aliasing=True,) for image in images])), (0, 3, 1, 2))\n",
        "    masks = torch.FloatTensor(np.array([resize(mask, size, mode='constant', anti_aliasing=False) > 0.5 for mask in masks])).unsqueeze(1)\n",
        "\n",
        "    # 데이터셋을 무작위로 섞고, train_part 비율에 따라 학습용 데이터와 테스트용 데이터로 나눔\n",
        "\n",
        "    indices = np.random.permutation(range(len(images)))\n",
        "    train_part = int(train_part * len(images))\n",
        "    train_ind = indices[:train_part]\n",
        "    test_ind = indices[train_part:]\n",
        "\n",
        "    # 학습 데이터셋과 테스트 데이터셋을 반환\n",
        "\n",
        "    train_dataset = (images[train_ind, :, :, :], masks[train_ind, :, :, :])\n",
        "    test_dataset = (images[test_ind, :, :, :], masks[test_ind, :, :, :])\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "train_dataset, test_dataset = load_dataset(train_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "데이터 집합의 일부 이미지를 플롯하여 어떻게 보이는지 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T16:03:58.259127Z",
          "iopub.status.busy": "2022-04-08T16:03:58.258819Z",
          "iopub.status.idle": "2022-04-08T16:03:58.266433Z",
          "shell.execute_reply": "2022-04-08T16:03:58.265489Z",
          "shell.execute_reply.started": "2022-04-08T16:03:58.259090Z"
        },
        "id": "jP2_-AjIFMpO",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m         ax1[i]\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow() \u001b[38;5;66;03m# 플롯을 화면에 표시\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m plotn(\u001b[38;5;241m5\u001b[39m, \u001b[43mtrain_dataset\u001b[49m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "# 주어진 데이터셋에서 이미지와 마스크를 시각화하는 기능을 수행\n",
        "\n",
        "def plotn(n, data, only_mask=False): # n은 표시할 이미지와 마스크의 수, data는 이미지와 마스크 데이터셋, only_mask는 마스크만 표시할지 여부를 결정하는 플래그\n",
        "    images, masks = data[0], data[1] # data에서 이미지와 마스크를 분리\n",
        "    fig, ax = plt.subplots(1, n) # 이미지를 표시할 서브플롯을 생성\n",
        "    fig1, ax1 = plt.subplots(1, n) # 마스크를 표시할 서브플롯을 생성\n",
        "    for i, (img, mask) in enumerate(zip(images, masks)): # 이미지를 순회하면서 표시\n",
        "        if i == n: # n개까지만 표시\n",
        "            break\n",
        "        if not only_mask: # only_mask가 False이면 이미지를 표시\n",
        "            ax[i].imshow(torch.permute(img, (1, 2, 0)))\n",
        "        else: # only_mask가 True이면 첫 번째 채널만 표시\n",
        "            ax[i].imshow(img[0])\n",
        "        ax1[i].imshow(mask[0]) # 마스크를 표시\n",
        "        ax[i].axis('off') # 축을 숨김\n",
        "        ax1[i].axis('off')\n",
        "    plt.show() # 플롯을 화면에 표시\n",
        "\n",
        "plotn(5, train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "신경망에 데이터를 공급하기 위해 데이터 로더가 필요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T16:03:58.247264Z",
          "iopub.status.busy": "2022-04-08T16:03:58.246853Z",
          "iopub.status.idle": "2022-04-08T16:03:58.256661Z",
          "shell.execute_reply": "2022-04-08T16:03:58.255964Z",
          "shell.execute_reply.started": "2022-04-08T16:03:58.247222Z"
        },
        "id": "rUGDAa61FMpN",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# PyTorch의 DataLoader를 사용하여 학습 데이터셋과 테스트 데이터셋을 배치로 로드\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# torch.utils.data.DataLoader를 사용하여 학습 데이터셋의 데이터 로더를 만듦\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# list(zip(train_dataset[0], train_dataset[1])): 학습 이미지와 마스크를 쌍으로 묶어 리스트로 만듦\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# batch_size=batch_size: 배치 크기를 batch_size로 설정\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# shuffle=True: 데이터셋을 섞어서 배치를 만듭니다. 이는 모델 학습 시 데이터의 순서로 인한 편향을 방지\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[43mtrain_dataset\u001b[49m[\u001b[38;5;241m0\u001b[39m], train_dataset[\u001b[38;5;241m1\u001b[39m])), batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# torch.utils.data.DataLoader를 사용하여 테스트 데이터셋의 데이터 로더를 만듦\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# list(zip(test_dataset[0], test_dataset[1])): 테스트 이미지와 마스크를 쌍으로 묶어 리스트로 만듦\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# batch_size=1: 배치 크기를 1로 설정 - 이는 보통 테스트 시 각 샘플을 개별적으로 평가하기 위해 사용\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# shuffle=False: 데이터셋을 섞지 않고 순서대로 배치를 만듦 - 이는 테스트 데이터의 순서를 유지하기 위해 사용\u001b[39;00m\n\u001b[1;32m     15\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(test_dataset[\u001b[38;5;241m0\u001b[39m], test_dataset[\u001b[38;5;241m1\u001b[39m])), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "# PyTorch의 DataLoader를 사용하여 학습 데이터셋과 테스트 데이터셋을 배치로 로드\n",
        "\n",
        "# torch.utils.data.DataLoader를 사용하여 학습 데이터셋의 데이터 로더를 만듦\n",
        "# list(zip(train_dataset[0], train_dataset[1])): 학습 이미지와 마스크를 쌍으로 묶어 리스트로 만듦\n",
        "# batch_size=batch_size: 배치 크기를 batch_size로 설정\n",
        "# shuffle=True: 데이터셋을 섞어서 배치를 만듭니다. 이는 모델 학습 시 데이터의 순서로 인한 편향을 방지\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(list(zip(train_dataset[0], train_dataset[1])), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# torch.utils.data.DataLoader를 사용하여 테스트 데이터셋의 데이터 로더를 만듦\n",
        "# list(zip(test_dataset[0], test_dataset[1])): 테스트 이미지와 마스크를 쌍으로 묶어 리스트로 만듦\n",
        "# batch_size=1: 배치 크기를 1로 설정 - 이는 보통 테스트 시 각 샘플을 개별적으로 평가하기 위해 사용\n",
        "# shuffle=False: 데이터셋을 섞지 않고 순서대로 배치를 만듦 - 이는 테스트 데이터의 순서를 유지하기 위해 사용\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(list(zip(test_dataset[0], test_dataset[1])), batch_size=1, shuffle=False)\n",
        "\n",
        "# train_dataloader와 test_dataloader를 튜플로 묶어 dataloaders로 저장 - 이를 통해 학습과 테스트 데이터 로더를 한 번에 관리\n",
        "\n",
        "dataloaders = (train_dataloader, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORmas8XhYfS8"
      },
      "source": [
        "## SegNet\n",
        "\n",
        "- 가장 간단한 인코더-디코더 아키텍처는 **SegNet**이라고 함\n",
        "- 인코더에는 컨볼루션과 풀링이 포함된 표준 CNN을 사용하고, 디코더에는 컨볼루션과 업샘플링이 포함된 디컨볼루션 CNN을 사용\n",
        "- 또한 다층 네트워크를 성공적으로 훈련하기 위해 배치 정규화에 의존"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T16:03:59.239435Z",
          "iopub.status.busy": "2022-04-08T16:03:59.239186Z",
          "iopub.status.idle": "2022-04-08T16:03:59.257319Z",
          "shell.execute_reply": "2022-04-08T16:03:59.256388Z",
          "shell.execute_reply.started": "2022-04-08T16:03:59.239401Z"
        },
        "id": "QDsSrmbeTbp9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# PyTorch를 사용하여 정의된 SegNet 아키텍처\n",
        "# SegNet은 이미지 분할을 위한 신경망\n",
        "# SegNet의 인코더-디코더 구조를 정의\n",
        "\n",
        "class SegNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # 인코더 (Encoder)\n",
        "        # 이미지의 중요한 특징을 추출\n",
        "        # 여러 개의 Conv2d, ReLU, BatchNorm2d, 그리고 MaxPool2d 레이어로 구성\n",
        "        # 각 인코딩 단계는 컨볼루션 연산 후 활성화 함수(ReLU)와 배치 정규화를 거치고, 마지막으로 맥스 풀링을 통해 차원을 축소\n",
        "        \n",
        "        self.enc_conv0 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3,3), padding=1)\n",
        "        self.act0 = nn.ReLU()\n",
        "        self.bn0 = nn.BatchNorm2d(16)\n",
        "        self.pool0 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "        self.enc_conv1 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), padding=1)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "        self.enc_conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=1)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 =  nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "        self.enc_conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding=1)\n",
        "        self.act3 = nn.ReLU()\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 =  nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "        # 병목 (Bottleneck)\n",
        "        # 인코더와 디코더 사이에서 가장 중요한 특징을 압축하고 전달\n",
        "        # 하나의 Conv2d 레이어로 구성\n",
        "\n",
        "        self.bottleneck_conv = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), padding=1)\n",
        "        \n",
        "        # 디코더 (Decoder)\n",
        "        # 인코더에서 추출된 특징을 사용하여 원본 이미지의 해상도와 유사하게 복원\n",
        "        # 여러 개의 업샘플링(UpsamplingBilinear2d)과 Conv2d, ReLU, BatchNorm2d 레이어로 구성\n",
        "        # 마지막 레이어는 컨볼루션을 통해 출력 채널을 1로 줄이고, 시그모이드 활성화 함수를 통해 결과를 이진화\n",
        "\n",
        "        self.upsample0 =  nn.UpsamplingBilinear2d(scale_factor=2)\n",
        "        self.dec_conv0 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=(3,3), padding=1)\n",
        "        self.dec_act0 = nn.ReLU()\n",
        "        self.dec_bn0 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.upsample1 =  nn.UpsamplingBilinear2d(scale_factor=2)\n",
        "        self.dec_conv1 =  nn.Conv2d(in_channels=128, out_channels=64, kernel_size=(3,3), padding=1)\n",
        "        self.dec_act1 = nn.ReLU()\n",
        "        self.dec_bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
        "        \n",
        "        self.dec_conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=(3,3), padding=1)\n",
        "        self.dec_act2 = nn.ReLU()\n",
        "        self.dec_bn2 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.upsample3 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
        "        self.dec_conv3 = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=(1,1))\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Forward 함수\n",
        "    # 입력 이미지를 받아 인코더를 거친 후 병목을 통해 압축하고, 디코더를 거쳐 출력 이미지를 생성 - 이 함수는 모델의 순전파 과정을 정의\n",
        "\n",
        "    def forward(self, x):\n",
        "        e0 = self.pool0(self.bn0(self.act0(self.enc_conv0(x))))\n",
        "        e1 = self.pool1(self.bn1(self.act1(self.enc_conv1(e0))))\n",
        "        e2 = self.pool2(self.bn2(self.act2(self.enc_conv2(e1))))\n",
        "        e3 = self.pool3(self.bn3(self.act3(self.enc_conv3(e2))))\n",
        "\n",
        "        b = self.bottleneck_conv(e3)\n",
        "\n",
        "        d0 = self.dec_bn0(self.dec_act0(self.dec_conv0(self.upsample0(b))))\n",
        "        d1 = self.dec_bn1(self.dec_act1(self.dec_conv1(self.upsample1(d0))))\n",
        "        d2 = self.dec_bn2(self.dec_act2(self.dec_conv2(self.upsample2(d1))))\n",
        "        d3 = self.sigmoid(self.dec_conv3(self.upsample3(d2)))\n",
        "        return d3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Segmentation에 사용되는 손실 함수\n",
        "- autoencoder에서는 두 이미지 간의 유사성을 측정해야 하며, 이를 위해 평균 제곱 오차를 사용할 수 있음\n",
        "- Segmentation에서 대상 마스크 이미지의 각 픽셀은 클래스 번호(3차원을 따라 한 번 핫 인코딩됨)를 나타내므로 분류에 특화된 손실 함수인 교차 엔트로피 손실(모든 픽셀에 평균을 낸 값)을 사용\n",
        "- 마스크가 2진수인 경우에는 **2진수 교차 엔트로피 손실**(BCE)을 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T16:03:59.259154Z",
          "iopub.status.busy": "2022-04-08T16:03:59.258856Z",
          "iopub.status.idle": "2022-04-08T16:03:59.284201Z",
          "shell.execute_reply": "2022-04-08T16:03:59.283559Z",
          "shell.execute_reply.started": "2022-04-08T16:03:59.259108Z"
        },
        "id": "2GoR8-huFMpn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# SegNet 모델을 생성하고, 최적화 함수와 손실 함수를 설정하는 과정\n",
        "\n",
        "model = SegNet().to(device) # # SegNet 모델 생성 및 장치로 이동\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay) # # Adam 최적화 함수 설정\n",
        "loss_fn = nn.BCEWithLogitsLoss() # # 이진 교차 엔트로피 손실 함수 설정 (로그잇 함수와 함께 사용)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "학습 루프는 일반적인 방식으로 정의됨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T16:03:59.286008Z",
          "iopub.status.busy": "2022-04-08T16:03:59.285826Z",
          "iopub.status.idle": "2022-04-08T16:03:59.298404Z",
          "shell.execute_reply": "2022-04-08T16:03:59.297656Z",
          "shell.execute_reply.started": "2022-04-08T16:03:59.285986Z"
        },
        "id": "HQ_UFglyTbqM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# SegNet 모델을 학습하는 train 함수를 정의\n",
        "# 이 함수는 주어진 데이터 로더, 모델, 손실 함수, 최적화 함수 및 에포크 수를 사용하여 모델을 학습하고 검증\n",
        "# 진행 상황은 tqdm 라이브러리를 통해 시각적으로 표시\n",
        "\n",
        "def train(dataloaders, model, loss_fn, optimizer, epochs, device): # 주어진 인자를 사용하여 모델을 학습\n",
        "    tqdm_iter = tqdm(range(epochs)) # 학습 진행을 시각적으로 표시하기 위해 tqdm 라이브러리를 사용\n",
        "    train_dataloader, test_dataloader = dataloaders[0], dataloaders[1]\n",
        "\n",
        "    for epoch in tqdm_iter: # 지정된 에포크 수만큼 반복\n",
        "        model.train() # 모델을 학습 모드로 설정\n",
        "        train_loss = 0.0 # 학습 손실 초기화\n",
        "        test_loss = 0.0 # 테스트 손실 초기화\n",
        "\n",
        "        for batch in train_dataloader: # 학습 데이터 로더에서 배치를 반복\n",
        "            imgs, labels = batch\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            preds = model(imgs) # 모델에 이미지 전달하여 예측 생성\n",
        "            loss = loss_fn(preds, labels) # 손실 계산\n",
        "\n",
        "            optimizer.zero_grad() # 옵티마이저 초기화\n",
        "            loss.backward() # 역전파\n",
        "            optimizer.step() # 가중치 업데이트\n",
        "\n",
        "            train_loss += loss.item() # 배치 손실을 학습 손실에 추가\n",
        "\n",
        "        model.eval() # 모델을 평가 모드로 설정\n",
        "        with torch.no_grad(): # 검증 단계에서는 그래디언트를 계산하지 않음\n",
        "            for batch in test_dataloader: # 테스트 데이터 로더에서 배치를 반복\n",
        "                imgs, labels = batch\n",
        "                imgs = imgs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                preds = model(imgs)\n",
        "                loss = loss_fn(preds, labels)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_dataloader) # 학습 손실 평균\n",
        "        test_loss /= len(test_dataloader) # 테스트 손실 평균\n",
        "\n",
        "        tqdm_dct = {'train loss:': train_loss, 'test loss:': test_loss} # 손실 값을 딕셔너리에 저장\n",
        "        tqdm_iter.set_postfix(tqdm_dct, refresh=True) # tqdm 진행 표시줄을 업데이트\n",
        "        tqdm_iter.refresh() # tqdm 진행 표시줄을 새로 고침"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-04-08T16:03:59.302207Z",
          "iopub.status.busy": "2022-04-08T16:03:59.301979Z",
          "iopub.status.idle": "2022-04-08T16:17:44.792683Z",
          "shell.execute_reply": "2022-04-08T16:17:44.791975Z",
          "shell.execute_reply.started": "2022-04-08T16:03:59.302184Z"
        },
        "id": "MsgM_kZRFMpo",
        "outputId": "8ff2de4a-ad8d-4b57-bdeb-ecaa90f742e2",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dataloaders' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train 함수를 실행하여 SegNet 모델을 학습\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 주어진 데이터 로더, 모델, 손실 함수, 최적화 함수, 에포크 수, 그리고 장치 정보를 사용하여 학습 과정을 진행\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m train(\u001b[43mdataloaders\u001b[49m, model, loss_fn, optimizer, epochs, device)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataloaders' is not defined"
          ]
        }
      ],
      "source": [
        "# train 함수를 실행하여 SegNet 모델을 학습\n",
        "# 주어진 데이터 로더, 모델, 손실 함수, 최적화 함수, 에포크 수, 그리고 장치 정보를 사용하여 학습 과정을 진행\n",
        "\n",
        "train(dataloaders, model, loss_fn, optimizer, epochs, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "모델을 평가하기 위해 여러 이미지에 대한 대상 마스크와 예상 마스크를 플로팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "execution": {
          "iopub.execute_input": "2022-04-08T16:17:44.795590Z",
          "iopub.status.busy": "2022-04-08T16:17:44.794942Z",
          "iopub.status.idle": "2022-04-08T16:17:45.663916Z",
          "shell.execute_reply": "2022-04-08T16:17:45.663160Z",
          "shell.execute_reply.started": "2022-04-08T16:17:44.795550Z"
        },
        "id": "FXvR7P1FFMpo",
        "outputId": "16b1f56d-93e0-48a0-d0c2-a8214b537741",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test_dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m image_mask \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m plots \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 8\u001b[0m images, masks \u001b[38;5;241m=\u001b[39m \u001b[43mtest_dataset\u001b[49m[\u001b[38;5;241m0\u001b[39m], test_dataset[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# images와 masks는 테스트 데이터셋에서 이미지를 가져옮\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (img, mask) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(images, masks)): \u001b[38;5;66;03m# 테스트 데이터셋에서 일부 이미지를 반복\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m plots: \u001b[38;5;66;03m# 시각화할 이미지 수를 plots로 제한\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "# SegNet 모델을 평가 모드로 설정하고 테스트 데이터셋에 대해 예측을 생성한 후, 일부 예측된 마스크를 시각화\n",
        "# plotn 함수는 only_mask=True 설정으로 예측된 마스크만 시각화\n",
        "\n",
        "model.eval() # 모델을 평가 모드로 설정 - 평가 모드에서는 드롭아웃 및 배치 정규화 레이어가 학습 시와 다르게 작동\n",
        "predictions = [] # 리스트를 초기화\n",
        "image_mask = []\n",
        "plots = 5\n",
        "images, masks = test_dataset[0], test_dataset[1] # images와 masks는 테스트 데이터셋에서 이미지를 가져옮\n",
        "for i, (img, mask) in enumerate(zip(images, masks)): # 테스트 데이터셋에서 일부 이미지를 반복\n",
        "    if i == plots: # 시각화할 이미지 수를 plots로 제한\n",
        "        break\n",
        "    img = img.to(device).unsqueeze(0) # 이미지를 지정된 장치로 이동시키고 배치 차원을 추가\n",
        "    predictions.append((model(img).detach().cpu()[0] > 0.5).float()) # 모델에 이미지를 전달하여 예측을 생성하고, 시그모이드 활성화 함수를 적용한 후 이진화하여 리스트에 추가\n",
        "    image_mask.append(mask) # 실제 마스크를 리스트에 추가\n",
        "plotn(plots, (predictions, image_mask), only_mask=True) # plotn 함수를 호출하여 예측된 마스크와 실제 마스크를 시각화 - only_mask=True로 설정하여 마스크만 표시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SemanticSegmentation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
